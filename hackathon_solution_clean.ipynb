{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "047ec15b",
   "metadata": {},
   "source": [
    "# Self-Improving AI Tutor with Multi-Agent System and Qdrant\n",
    "\n",
    "This notebook implements a complete adaptive tutoring system that:\n",
    "- Generates lesson plans from PDF content\n",
    "- Uses multiple AI agents that learn from experience\n",
    "- Adapts teaching style based on student emotions\n",
    "- Stores all learning experiences in Qdrant vector database\n",
    "- Includes quiz systems and progress tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cfce30",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8aa908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "! pip install qdrant-client groq pymupdf text2emotion swarm python-dotenv Pillow numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ee66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install swarm from GitHub\n",
    "! pip install git+https://github.com/openai/swarm.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd4699",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906ced28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from groq import Groq\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    Distance, VectorParams, PointStruct, Filter, \n",
    "    FieldCondition, MatchValue, PayloadSchemaType\n",
    ")\n",
    "import uuid\n",
    "import json\n",
    "import time\n",
    "import base64\n",
    "import io\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import text2emotion as te\n",
    "from PIL import Image\n",
    "from swarm import Swarm, Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39abf135",
   "metadata": {},
   "source": [
    "## Step 3: Configuration and Initialize Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d645e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Keys\n",
    "GROQ_API_KEY = \"YOUR_GROQ_API_KEY\"\n",
    "QDRANT_URL = \"YOUR_QDRANT_URL\"\n",
    "QDRANT_API_KEY = \"YOUR_QDRANT_API_KEY\"\n",
    "\n",
    "# Initialize clients\n",
    "groq_client = Groq(api_key=GROQ_API_KEY)\n",
    "qdrant_client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
    "swarm_client = Swarm(client=groq_client)\n",
    "\n",
    "# Configuration\n",
    "GROQ_MODEL = \"llama-3.3-70b-versatile\"\n",
    "EMBEDDING_DIM = 384\n",
    "COLLECTION_PDF_CONTENT = \"pdf_content_sequential\"\n",
    "COLLECTION_TEACHING_STYLES = \"teaching_styles\"\n",
    "COLLECTION_STUDENT_MEMORY = \"student_memory\"\n",
    "COLLECTION_AGENT_LEARNING = \"agent_learning\"\n",
    "COLLECTION_PDF_IMAGES = \"pdf_images\"\n",
    "\n",
    "print(f\"Configuration complete\")\n",
    "print(f\"Embedding dimension: {EMBEDDING_DIM}\")\n",
    "print(f\"Collections: {5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68047d99",
   "metadata": {},
   "source": [
    "## Step 4: Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_embed(text: str, dim: int = 384) -> List[float]:\n",
    "    \"\"\"\n",
    "    Create embeddings using hash-based approach.\n",
    "    Simple and fast, no PyTorch dependencies needed.\n",
    "    \"\"\"\n",
    "    words = text.lower().split()\n",
    "    vector = [0.0] * dim\n",
    "    \n",
    "    for i, word in enumerate(words[:100]):\n",
    "        hash_val = hash(word)\n",
    "        for j in range(3):\n",
    "            idx = (hash_val + j * 13) % dim\n",
    "            vector[idx] += 1.0 / (i + 1)\n",
    "    \n",
    "    # Normalize\n",
    "    norm = np.sqrt(sum(v*v for v in vector))\n",
    "    if norm > 0:\n",
    "        vector = [v/norm for v in vector]\n",
    "    \n",
    "    return vector\n",
    "\n",
    "print(\"Embedding function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc0dd85",
   "metadata": {},
   "source": [
    "## Step 5: Setup Qdrant Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7bbb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_qdrant_collections():\n",
    "    \"\"\"\n",
    "    Create all 5 Qdrant collections with appropriate configurations\n",
    "    \"\"\"\n",
    "    collections = [\n",
    "        (COLLECTION_PDF_CONTENT, \"Sequential PDF content for teaching\"),\n",
    "        (COLLECTION_TEACHING_STYLES, \"Teaching styles mapped to emotions\"),\n",
    "        (COLLECTION_STUDENT_MEMORY, \"Student progress and preferences\"),\n",
    "        (COLLECTION_AGENT_LEARNING, \"Agent learning experiences and outcomes\"),\n",
    "        (COLLECTION_PDF_IMAGES, \"PDF images with descriptions\")\n",
    "    ]\n",
    "    \n",
    "    for collection_name, description in collections:\n",
    "        try:\n",
    "            if qdrant_client.collection_exists(collection_name):\n",
    "                qdrant_client.delete_collection(collection_name)\n",
    "                print(f\"Deleted existing: {collection_name}\")\n",
    "            \n",
    "            qdrant_client.create_collection(\n",
    "                collection_name=collection_name,\n",
    "                vectors_config=VectorParams(size=EMBEDDING_DIM, distance=Distance.COSINE)\n",
    "            )\n",
    "            print(f\"Created: {collection_name}\")\n",
    "            \n",
    "            # Create indexes\n",
    "            if collection_name == COLLECTION_PDF_CONTENT:\n",
    "                qdrant_client.create_payload_index(\n",
    "                    collection_name=collection_name,\n",
    "                    field_name=\"sequence_id\",\n",
    "                    field_schema=PayloadSchemaType.INTEGER\n",
    "                )\n",
    "                qdrant_client.create_payload_index(\n",
    "                    collection_name=collection_name,\n",
    "                    field_name=\"difficulty\",\n",
    "                    field_schema=PayloadSchemaType.KEYWORD\n",
    "                )\n",
    "            elif collection_name == COLLECTION_AGENT_LEARNING:\n",
    "                qdrant_client.create_payload_index(\n",
    "                    collection_name=collection_name,\n",
    "                    field_name=\"agent_name\",\n",
    "                    field_schema=PayloadSchemaType.KEYWORD\n",
    "                )\n",
    "            elif collection_name == COLLECTION_PDF_IMAGES:\n",
    "                qdrant_client.create_payload_index(\n",
    "                    collection_name=collection_name,\n",
    "                    field_name=\"page\",\n",
    "                    field_schema=PayloadSchemaType.INTEGER\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error with {collection_name}: {e}\")\n",
    "    \n",
    "    print(\"\\nAll collections ready\")\n",
    "\n",
    "setup_qdrant_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0bd67c",
   "metadata": {},
   "source": [
    "## Step 6: PDF Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d8cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnhancedPDFProcessor:\n",
    "    \"\"\"\n",
    "    Process PDF files to extract text chunks and images\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def process_pdf(self, pdf_path: str) -> Tuple[List[Dict], List[Dict]]:\n",
    "        \"\"\"\n",
    "        Extract content and images from PDF with rich metadata\n",
    "        \"\"\"\n",
    "        doc = fitz.open(pdf_path)\n",
    "        text_chunks = []\n",
    "        images = []\n",
    "        chunk_id = 0\n",
    "        \n",
    "        print(f\"Processing PDF: {pdf_path}\")\n",
    "        print(f\"Total pages: {len(doc)}\")\n",
    "        \n",
    "        for page_num, page in enumerate(doc):\n",
    "            text = page.get_text()\n",
    "            \n",
    "            # Extract images\n",
    "            image_list = page.get_images(full=True)\n",
    "            for img_index, img in enumerate(image_list):\n",
    "                try:\n",
    "                    xref = img[0]\n",
    "                    base_image = doc.extract_image(xref)\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                    image_ext = base_image[\"ext\"]\n",
    "                    \n",
    "                    image_b64 = base64.b64encode(image_bytes).decode()\n",
    "                    description = f\"Image {len(images)+1} from page {page_num+1}\"\n",
    "                    vector = simple_embed(description)\n",
    "                    \n",
    "                    images.append({\n",
    "                        \"id\": str(uuid.uuid4()),\n",
    "                        \"vector\": vector,\n",
    "                        \"payload\": {\n",
    "                            \"description\": description,\n",
    "                            \"page\": page_num + 1,\n",
    "                            \"image_base64\": image_b64,\n",
    "                            \"image_format\": image_ext,\n",
    "                            \"image_index\": len(images)\n",
    "                        }\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Could not extract image {img_index} from page {page_num}: {e}\")\n",
    "            \n",
    "            # Split text into chunks\n",
    "            sentences = text.split('. ')\n",
    "            \n",
    "            for i in range(0, len(sentences), 3):\n",
    "                chunk_text = '. '.join(sentences[i:i+3]).strip()\n",
    "                \n",
    "                if len(chunk_text) < 20:\n",
    "                    continue\n",
    "                \n",
    "                vector = simple_embed(chunk_text)\n",
    "                word_count = len(chunk_text.split())\n",
    "                avg_word_length = np.mean([len(w) for w in chunk_text.split()]) if word_count > 0 else 0\n",
    "                difficulty = \"beginner\" if avg_word_length < 6 else \"intermediate\" if avg_word_length < 8 else \"advanced\"\n",
    "                \n",
    "                text_chunks.append({\n",
    "                    \"id\": str(uuid.uuid4()),\n",
    "                    \"vector\": vector,\n",
    "                    \"payload\": {\n",
    "                        \"text\": chunk_text,\n",
    "                        \"sequence_id\": chunk_id,\n",
    "                        \"page\": page_num + 1,\n",
    "                        \"word_count\": word_count,\n",
    "                        \"difficulty\": difficulty,\n",
    "                        \"timestamp\": datetime.now().isoformat()\n",
    "                    }\n",
    "                })\n",
    "                \n",
    "                chunk_id += 1\n",
    "        \n",
    "        doc.close()\n",
    "        print(f\"Extracted {len(text_chunks)} content chunks\")\n",
    "        print(f\"Extracted {len(images)} images\")\n",
    "        return text_chunks, images\n",
    "    \n",
    "    def ingest_to_qdrant(self, text_chunks: List[Dict], images: List[Dict]):\n",
    "        \"\"\"Upload chunks and images to Qdrant\"\"\"\n",
    "        if text_chunks:\n",
    "            text_points = [\n",
    "                PointStruct(id=chunk[\"id\"], vector=chunk[\"vector\"], payload=chunk[\"payload\"])\n",
    "                for chunk in text_chunks\n",
    "            ]\n",
    "            qdrant_client.upsert(collection_name=COLLECTION_PDF_CONTENT, points=text_points)\n",
    "            print(f\"Ingested {len(text_points)} text chunks to Qdrant\")\n",
    "        \n",
    "        if images:\n",
    "            image_points = [\n",
    "                PointStruct(id=img[\"id\"], vector=img[\"vector\"], payload=img[\"payload\"])\n",
    "                for img in images\n",
    "            ]\n",
    "            qdrant_client.upsert(collection_name=COLLECTION_PDF_IMAGES, points=image_points)\n",
    "            print(f\"Ingested {len(image_points)} images to Qdrant\")\n",
    "\n",
    "pdf_processor = EnhancedPDFProcessor()\n",
    "print(\"PDF Processor ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f5867",
   "metadata": {},
   "source": [
    "## Step 7: Initialize Teaching Styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2160f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_teaching_styles():\n",
    "    \"\"\"\n",
    "    Pre-load teaching styles for different emotions\n",
    "    \"\"\"\n",
    "    styles = [\n",
    "        {\n",
    "            \"name\": \"Empathetic and Encouraging\",\n",
    "            \"emotion\": \"sad\",\n",
    "            \"description\": \"Gentle, supportive tone with positive reinforcement\",\n",
    "            \"characteristics\": \"Use encouraging words, acknowledge feelings, break down complex ideas\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Enthusiastic and Motivational\",\n",
    "            \"emotion\": \"happy\",\n",
    "            \"description\": \"Energetic, engaging tone that builds on positive momentum\",\n",
    "            \"characteristics\": \"Use exciting examples, challenge with interesting problems\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Patient and Clarifying\",\n",
    "            \"emotion\": \"angry\",\n",
    "            \"description\": \"Calm, clear explanations with extra patience\",\n",
    "            \"characteristics\": \"Simplify concepts, use multiple analogies\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Clear and Structured\",\n",
    "            \"emotion\": \"fear\",\n",
    "            \"description\": \"Reassuring, well-organized explanations\",\n",
    "            \"characteristics\": \"Step-by-step approach, predictable structure\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Balanced and Informative\",\n",
    "            \"emotion\": \"neutral\",\n",
    "            \"description\": \"Standard teaching approach with good examples\",\n",
    "            \"characteristics\": \"Clear explanations, relevant examples\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    points = []\n",
    "    for style in styles:\n",
    "        text_for_embedding = f\"{style['description']} {style['characteristics']}\"\n",
    "        vector = simple_embed(text_for_embedding)\n",
    "        points.append(PointStruct(id=str(uuid.uuid4()), vector=vector, payload=style))\n",
    "    \n",
    "    qdrant_client.upsert(collection_name=COLLECTION_TEACHING_STYLES, points=points)\n",
    "    print(f\"Initialized {len(styles)} teaching styles\")\n",
    "\n",
    "initialize_teaching_styles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905c74d3",
   "metadata": {},
   "source": [
    "## Step 8: Core Helper Functions\n",
    "\n",
    "These functions must be defined before the agents, as agents will call them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0698b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_emotion(text: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Detect emotion from student's text using text2emotion library\n",
    "    Returns dominant emotion and all scores\n",
    "    \"\"\"\n",
    "    try:\n",
    "        emotions = te.get_emotion(text)\n",
    "        dominant_emotion = max(emotions.items(), key=lambda x: x[1])[0]\n",
    "        return {\n",
    "            \"dominant\": dominant_emotion,\n",
    "            \"scores\": emotions\n",
    "        }\n",
    "    except:\n",
    "        return {\n",
    "            \"dominant\": \"neutral\",\n",
    "            \"scores\": {}\n",
    "        }\n",
    "\n",
    "# Shared context for agents\n",
    "agent_context = {\n",
    "    \"current_student\": None,\n",
    "    \"current_topic\": None,\n",
    "    \"conversation_history\": [],\n",
    "    \"session_metrics\": defaultdict(list)\n",
    "}\n",
    "\n",
    "def query_pdf_content(sequence_id: Optional[int] = None, \n",
    "                     topic_search: Optional[str] = None,\n",
    "                     difficulty: Optional[str] = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Query PDF content from Qdrant by sequence ID or semantic search\n",
    "    \"\"\"\n",
    "    if topic_search:\n",
    "        query_vector = simple_embed(topic_search)\n",
    "        filter_conditions = []\n",
    "        \n",
    "        if difficulty:\n",
    "            filter_conditions.append(\n",
    "                FieldCondition(key=\"difficulty\", match=MatchValue(value=difficulty))\n",
    "            )\n",
    "        \n",
    "        results = qdrant_client.query_points(\n",
    "            collection_name=COLLECTION_PDF_CONTENT,\n",
    "            query=query_vector,\n",
    "            query_filter=Filter(must=filter_conditions) if filter_conditions else None,\n",
    "            limit=1\n",
    "        )\n",
    "        \n",
    "        if results.points:\n",
    "            return results.points[0].payload\n",
    "    \n",
    "    elif sequence_id is not None:\n",
    "        results = qdrant_client.scroll(\n",
    "            collection_name=COLLECTION_PDF_CONTENT,\n",
    "            scroll_filter=Filter(\n",
    "                must=[FieldCondition(key=\"sequence_id\", match=MatchValue(value=sequence_id))]\n",
    "            ),\n",
    "            limit=1\n",
    "        )\n",
    "        \n",
    "        if results[0]:\n",
    "            return results[0][0].payload\n",
    "    \n",
    "    return {\"text\": \"No content found\", \"sequence_id\": -1}\n",
    "\n",
    "def query_teaching_style(emotion: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Get appropriate teaching style for given emotion from Qdrant\n",
    "    \"\"\"\n",
    "    emotion_query = f\"Teaching style for {emotion} emotion\"\n",
    "    query_vector = simple_embed(emotion_query)\n",
    "    \n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=COLLECTION_TEACHING_STYLES,\n",
    "        query=query_vector,\n",
    "        limit=1\n",
    "    )\n",
    "    \n",
    "    if results.points:\n",
    "        return results.points[0].payload\n",
    "    \n",
    "    return {\n",
    "        \"name\": \"Balanced\",\n",
    "        \"description\": \"Standard teaching approach\",\n",
    "        \"characteristics\": \"Clear explanations with examples\"\n",
    "    }\n",
    "\n",
    "def query_related_images(page_num: int) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Query images from specific page for whiteboard display\n",
    "    \"\"\"\n",
    "    results = qdrant_client.scroll(\n",
    "        collection_name=COLLECTION_PDF_IMAGES,\n",
    "        scroll_filter=Filter(\n",
    "            must=[FieldCondition(key=\"page\", match=MatchValue(value=page_num))]\n",
    "        ),\n",
    "        limit=5\n",
    "    )\n",
    "    \n",
    "    images = []\n",
    "    if results[0]:\n",
    "        for point in results[0]:\n",
    "            images.append({\n",
    "                \"description\": point.payload.get(\"description\"),\n",
    "                \"image_base64\": point.payload.get(\"image_base64\"),\n",
    "                \"image_format\": point.payload.get(\"image_format\")\n",
    "            })\n",
    "    \n",
    "    return images\n",
    "\n",
    "print(\"Helper functions defined successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573917ff",
   "metadata": {},
   "source": [
    "## Step 9: Student Memory System\n",
    "\n",
    "Tracks individual student progress and preferences in Qdrant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00a3c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentMemorySystem:\n",
    "    \"\"\"\n",
    "    Track student progress, preferences, and learning history\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def _get_uuid_from_string(self, string_id: str) -> str:\n",
    "        \"\"\"Generate consistent UUID from string ID\"\"\"\n",
    "        return str(uuid.uuid5(uuid.NAMESPACE_DNS, string_id))\n",
    "    \n",
    "    def initialize_student(self, student_id: str):\n",
    "        \"\"\"Create initial student profile in Qdrant\"\"\"\n",
    "        vector = simple_embed(f\"Student profile: {student_id}\")\n",
    "        point_id = self._get_uuid_from_string(student_id)\n",
    "        \n",
    "        point = PointStruct(\n",
    "            id=point_id,\n",
    "            vector=vector,\n",
    "            payload={\n",
    "                \"student_id\": student_id,\n",
    "                \"topics_covered\": [],\n",
    "                \"confusion_points\": [],\n",
    "                \"mastered_topics\": [],\n",
    "                \"preferred_styles\": [],\n",
    "                \"total_interactions\": 0,\n",
    "                \"start_time\": datetime.now().isoformat()\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        qdrant_client.upsert(\n",
    "            collection_name=COLLECTION_STUDENT_MEMORY,\n",
    "            points=[point]\n",
    "        )\n",
    "        print(f\"Student initialized: {student_id}\")\n",
    "    \n",
    "    def update_student_progress(self, student_id: str, topic: str, \n",
    "                               understood: bool, emotion: str, style_used: str):\n",
    "        \"\"\"Update student's learning progress\"\"\"\n",
    "        point_id = self._get_uuid_from_string(student_id)\n",
    "        \n",
    "        result = qdrant_client.retrieve(\n",
    "            collection_name=COLLECTION_STUDENT_MEMORY,\n",
    "            ids=[point_id]\n",
    "        )\n",
    "        \n",
    "        if result:\n",
    "            current_payload = result[0].payload\n",
    "            \n",
    "            if topic not in current_payload[\"topics_covered\"]:\n",
    "                current_payload[\"topics_covered\"].append(topic)\n",
    "            \n",
    "            if understood:\n",
    "                if topic not in current_payload[\"mastered_topics\"]:\n",
    "                    current_payload[\"mastered_topics\"].append(topic)\n",
    "            else:\n",
    "                if topic not in current_payload[\"confusion_points\"]:\n",
    "                    current_payload[\"confusion_points\"].append(topic)\n",
    "            \n",
    "            if style_used not in current_payload[\"preferred_styles\"]:\n",
    "                current_payload[\"preferred_styles\"].append(style_used)\n",
    "            \n",
    "            current_payload[\"total_interactions\"] += 1\n",
    "            current_payload[\"last_emotion\"] = emotion\n",
    "            current_payload[\"last_update\"] = datetime.now().isoformat()\n",
    "            \n",
    "            progress_text = f\"Student {student_id}: {len(current_payload['mastered_topics'])} mastered\"\n",
    "            vector = simple_embed(progress_text)\n",
    "            \n",
    "            qdrant_client.upsert(\n",
    "                collection_name=COLLECTION_STUDENT_MEMORY,\n",
    "                points=[PointStruct(\n",
    "                    id=point_id,\n",
    "                    vector=vector,\n",
    "                    payload=current_payload\n",
    "                )]\n",
    "            )\n",
    "    \n",
    "    def get_student_profile(self, student_id: str) -> Dict:\n",
    "        \"\"\"Retrieve complete student profile\"\"\"\n",
    "        point_id = self._get_uuid_from_string(student_id)\n",
    "        result = qdrant_client.retrieve(\n",
    "            collection_name=COLLECTION_STUDENT_MEMORY,\n",
    "            ids=[point_id]\n",
    "        )\n",
    "        return result[0].payload if result else None\n",
    "    \n",
    "    def recommend_next_topic(self, student_id: str) -> Dict:\n",
    "        \"\"\"Recommend next topic based on progress\"\"\"\n",
    "        profile = self.get_student_profile(student_id)\n",
    "        \n",
    "        if not profile:\n",
    "            return {\n",
    "                \"recommendation\": \"Start from beginning\",\n",
    "                \"reason\": \"New student\",\n",
    "                \"type\": \"new\",\n",
    "                \"sequence_id\": 0\n",
    "            }\n",
    "        \n",
    "        topics_covered = len(profile.get(\"topics_covered\", []))\n",
    "        confusion_points = profile.get(\"confusion_points\", [])\n",
    "        \n",
    "        if confusion_points:\n",
    "            return {\n",
    "                \"recommendation\": confusion_points[-1],\n",
    "                \"reason\": \"Review confused topic\",\n",
    "                \"type\": \"review\"\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"recommendation\": f\"Topic {topics_covered + 1}\",\n",
    "            \"reason\": \"Continue progression\",\n",
    "            \"type\": \"next\",\n",
    "            \"sequence_id\": topics_covered\n",
    "        }\n",
    "\n",
    "memory_system = StudentMemorySystem()\n",
    "print(\"Student Memory System initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d8f314",
   "metadata": {},
   "source": [
    "## Step 10: Agent Learning System\n",
    "\n",
    "This is the KEY INNOVATION - agents store experiences and learn from past successes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f787ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentLearningSystem:\n",
    "    \"\"\"\n",
    "    Stores and retrieves agent experiences for continuous improvement.\n",
    "    This enables true agent learning, not just retrieval.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def store_experience(self, agent_name: str, situation: str, action: str, \n",
    "                        outcome_score: float, metadata: Dict):\n",
    "        \"\"\"\n",
    "        Store teaching experience in Qdrant for future learning\n",
    "        \n",
    "        Args:\n",
    "            agent_name: Which agent took the action\n",
    "            situation: Description of the context\n",
    "            action: What action was taken\n",
    "            outcome_score: Success metric (0-1)\n",
    "            metadata: Additional context\n",
    "        \"\"\"\n",
    "        experience_text = f\"{situation} | Action: {action}\"\n",
    "        vector = simple_embed(experience_text)\n",
    "        \n",
    "        payload = {\n",
    "            \"agent_name\": agent_name,\n",
    "            \"situation\": situation,\n",
    "            \"action\": action,\n",
    "            \"outcome_score\": outcome_score,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            **metadata\n",
    "        }\n",
    "        \n",
    "        point = PointStruct(\n",
    "            id=str(uuid.uuid4()),\n",
    "            vector=vector,\n",
    "            payload=payload\n",
    "        )\n",
    "        \n",
    "        qdrant_client.upsert(\n",
    "            collection_name=COLLECTION_AGENT_LEARNING,\n",
    "            points=[point]\n",
    "        )\n",
    "    \n",
    "    def retrieve_successful_strategies(self, agent_name: str, situation: str, \n",
    "                                      top_k: int = 3, min_score: float = 0.6):\n",
    "        \"\"\"\n",
    "        Retrieve past successful strategies for similar situations\n",
    "        This is how agents LEARN and EVOLVE\n",
    "        \"\"\"\n",
    "        query_vector = simple_embed(situation)\n",
    "        \n",
    "        results = qdrant_client.query_points(\n",
    "            collection_name=COLLECTION_AGENT_LEARNING,\n",
    "            query=query_vector,\n",
    "            query_filter=Filter(\n",
    "                must=[\n",
    "                    FieldCondition(\n",
    "                        key=\"agent_name\",\n",
    "                        match=MatchValue(value=agent_name)\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            limit=top_k\n",
    "        )\n",
    "        \n",
    "        successful_strategies = [\n",
    "            {\n",
    "                \"action\": hit.payload[\"action\"],\n",
    "                \"outcome_score\": hit.payload[\"outcome_score\"],\n",
    "                \"similarity\": hit.score,\n",
    "                \"metadata\": {k: v for k, v in hit.payload.items() \n",
    "                           if k not in [\"action\", \"outcome_score\", \"agent_name\", \"situation\"]}\n",
    "            }\n",
    "            for hit in results.points\n",
    "            if hit.payload.get(\"outcome_score\", 0) >= min_score\n",
    "        ]\n",
    "        \n",
    "        return successful_strategies\n",
    "    \n",
    "    def get_agent_performance_stats(self, agent_name: str) -> Dict:\n",
    "        \"\"\"Get performance statistics for an agent\"\"\"\n",
    "        results = qdrant_client.scroll(\n",
    "            collection_name=COLLECTION_AGENT_LEARNING,\n",
    "            scroll_filter=Filter(\n",
    "                must=[\n",
    "                    FieldCondition(\n",
    "                        key=\"agent_name\",\n",
    "                        match=MatchValue(value=agent_name)\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            limit=100\n",
    "        )\n",
    "        \n",
    "        if not results[0]:\n",
    "            return {\n",
    "                \"total_experiences\": 0,\n",
    "                \"avg_outcome\": 0,\n",
    "                \"success_rate\": 0\n",
    "            }\n",
    "        \n",
    "        outcomes = [point.payload.get(\"outcome_score\", 0) for point in results[0]]\n",
    "        \n",
    "        return {\n",
    "            \"total_experiences\": len(outcomes),\n",
    "            \"avg_outcome\": np.mean(outcomes) if outcomes else 0,\n",
    "            \"success_rate\": sum(1 for o in outcomes if o >= 0.7) / len(outcomes) if outcomes else 0\n",
    "        }\n",
    "\n",
    "learning_system = AgentLearningSystem()\n",
    "print(\"Agent Learning System initialized\")\n",
    "print(\"Agents can now store experiences and learn from past successes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d0b185",
   "metadata": {},
   "source": [
    "## Step 11: Privacy & Ethics Systems\n",
    "\n",
    "Responsible AI systems for educational context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f0a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrivacyManager:\n",
    "    \"\"\"Ensure student data privacy and consent\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.anonymization_enabled = True\n",
    "    \n",
    "    def anonymize_student_id(self, student_id: str) -> str:\n",
    "        \"\"\"Generate anonymous ID for external sharing\"\"\"\n",
    "        return hashlib.sha256(student_id.encode()).hexdigest()[:16]\n",
    "    \n",
    "    def filter_sensitive_data(self, data: Dict) -> Dict:\n",
    "        \"\"\"Remove sensitive information from data\"\"\"\n",
    "        filtered = data.copy()\n",
    "        sensitive_keys = [\"student_id\", \"email\", \"name\"]\n",
    "        for key in sensitive_keys:\n",
    "            if key in filtered:\n",
    "                filtered[key] = self.anonymize_student_id(str(filtered[key]))\n",
    "        return filtered\n",
    "\n",
    "class ConsentManager:\n",
    "    \"\"\"Track student consent for data usage\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.consent_records = {}\n",
    "    \n",
    "    def record_consent(self, student_id: str, consent_type: str, granted: bool):\n",
    "        \"\"\"Record student consent\"\"\"\n",
    "        if student_id not in self.consent_records:\n",
    "            self.consent_records[student_id] = {}\n",
    "        self.consent_records[student_id][consent_type] = {\n",
    "            \"granted\": granted,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    def has_consent(self, student_id: str, consent_type: str) -> bool:\n",
    "        \"\"\"Check if student has granted consent\"\"\"\n",
    "        return self.consent_records.get(student_id, {}).get(consent_type, {}).get(\"granted\", False)\n",
    "\n",
    "class BiasAuditor:\n",
    "    \"\"\"Monitor and mitigate bias in teaching\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.interaction_log = []\n",
    "    \n",
    "    def log_interaction(self, student_profile: Dict, content_delivered: Dict):\n",
    "        \"\"\"Log interaction for bias analysis\"\"\"\n",
    "        self.interaction_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"student_demographics\": student_profile.get(\"demographics\", {}),\n",
    "            \"content\": content_delivered,\n",
    "            \"difficulty\": content_delivered.get(\"difficulty\")\n",
    "        })\n",
    "    \n",
    "    def analyze_bias(self) -> Dict:\n",
    "        \"\"\"Analyze logged interactions for bias patterns\"\"\"\n",
    "        if not self.interaction_log:\n",
    "            return {\"status\": \"insufficient_data\"}\n",
    "        \n",
    "        return {\n",
    "            \"total_interactions\": len(self.interaction_log),\n",
    "            \"status\": \"monitored\",\n",
    "            \"recommendation\": \"Continue monitoring for patterns\"\n",
    "        }\n",
    "\n",
    "class ExplainabilityEngine:\n",
    "    \"\"\"Provide explanations for AI decisions\"\"\"\n",
    "    \n",
    "    def explain_recommendation(self, recommendation: Dict, context: Dict) -> str:\n",
    "        \"\"\"Generate human-readable explanation for recommendations\"\"\"\n",
    "        if recommendation.get(\"type\") == \"review\":\n",
    "            return f\"Recommending review of '{recommendation['recommendation']}' because the student showed confusion during the last session.\"\n",
    "        elif recommendation.get(\"type\") == \"next\":\n",
    "            return f\"Student has mastered {len(context.get('mastered_topics', []))} topics. Moving to next topic in sequence.\"\n",
    "        else:\n",
    "            return \"Starting with foundational content for new student.\"\n",
    "\n",
    "privacy_manager = PrivacyManager()\n",
    "consent_manager = ConsentManager()\n",
    "bias_auditor = BiasAuditor()\n",
    "explainability_engine = ExplainabilityEngine()\n",
    "\n",
    "print(\"Privacy & Ethics systems initialized\")\n",
    "print(\"All data handling will respect consent and privacy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70cd10a",
   "metadata": {},
   "source": [
    "## Step 12: OpenAI Swarm Agents\n",
    "\n",
    "Now we define the 6 specialized agents. All dependencies are already in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b946f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orchestrator_agent_logic(context_variables: Dict):\n",
    "    \"\"\"\n",
    "    Master agent that coordinates all other agents\n",
    "    Decides which agent should handle the student's current state\n",
    "    \"\"\"\n",
    "    student_message = context_variables.get(\"student_message\", \"\")\n",
    "    emotion_data = detect_emotion(student_message)\n",
    "    dominant_emotion = emotion_data[\"dominant\"]\n",
    "    \n",
    "    agent_context[\"current_emotion\"] = dominant_emotion\n",
    "    agent_context[\"conversation_history\"].append({\n",
    "        \"message\": student_message,\n",
    "        \"emotion\": dominant_emotion,\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "    \n",
    "    # Retrieve successful strategies for similar emotional states\n",
    "    past_strategies = learning_system.retrieve_successful_strategies(\n",
    "        agent_name=\"orchestrator\",\n",
    "        situation=f\"Student emotion: {dominant_emotion}\",\n",
    "        top_k=2\n",
    "    )\n",
    "    \n",
    "    strategy_context = \"\"\n",
    "    if past_strategies:\n",
    "        strategy_context = f\"\\nPrevious successful approaches: {past_strategies[0]['action']}\"\n",
    "    \n",
    "    decision = f\"\"\"Analyze the situation and decide next action:\n",
    "- Student emotion: {dominant_emotion}\n",
    "- Message: {student_message[:100]}\n",
    "{strategy_context}\n",
    "\n",
    "Choose appropriate agent: content_sequencer, emotion_analyzer, style_adapter, explainer, or memory_manager\"\"\"\n",
    "    \n",
    "    return Result(value=decision, agent=content_sequencer_agent)\n",
    "\n",
    "orchestrator_agent = Agent(\n",
    "    name=\"Orchestrator\",\n",
    "    instructions=\"\"\"You are the master coordinator of the teaching system.\n",
    "Analyze student state and route to appropriate specialized agent.\n",
    "Consider emotion, progress, and past successful strategies.\"\"\",\n",
    "    functions=[orchestrator_agent_logic]\n",
    ")\n",
    "\n",
    "def get_next_content(context_variables: Dict):\n",
    "    \"\"\"\n",
    "    Content Sequencer agent - decides what to teach next\n",
    "    Uses student memory and learning system for informed decisions\n",
    "    \"\"\"\n",
    "    student_id = context_variables.get(\"student_id\")\n",
    "    \n",
    "    if not student_id:\n",
    "        return Result(value=\"Please provide student ID to continue\")\n",
    "    \n",
    "    # Get student progress\n",
    "    student_profile = memory_system.get_student_profile(student_id)\n",
    "    \n",
    "    # Get past successful content sequencing strategies\n",
    "    past_strategies = learning_system.retrieve_successful_strategies(\n",
    "        agent_name=\"content_sequencer\",\n",
    "        situation=f\"Student progress: {len(student_profile.get('mastered_topics', []))} topics mastered\",\n",
    "        top_k=3\n",
    "    )\n",
    "    \n",
    "    # Get recommendation\n",
    "    next_topic = memory_system.recommend_next_topic(student_id)\n",
    "    \n",
    "    # Retrieve actual content from PDF\n",
    "    content = query_pdf_content(sequence_id=next_topic.get(\"sequence_id\", 0))\n",
    "    \n",
    "    strategy_notes = \"\"\n",
    "    if past_strategies:\n",
    "        strategy_notes = f\"\\nLearned approach: {past_strategies[0]['action']}\"\n",
    "    \n",
    "    result = f\"\"\"Next content recommendation:\n",
    "Topic: {next_topic['recommendation']}\n",
    "Reason: {next_topic['reason']}\n",
    "Content: {content.get('text', 'No content available')[:200]}\n",
    "{strategy_notes}\"\"\"\n",
    "    \n",
    "    # Store this decision for learning\n",
    "    learning_system.store_experience(\n",
    "        agent_name=\"content_sequencer\",\n",
    "        situation=f\"Sequenced content for student with {len(student_profile.get('topics_covered', []))} topics covered\",\n",
    "        action=f\"Recommended {next_topic['type']} content: {next_topic['recommendation']}\",\n",
    "        outcome_score=0.8,  # Will be updated based on student performance\n",
    "        metadata={\"topic\": next_topic['recommendation'], \"type\": next_topic['type']}\n",
    "    )\n",
    "    \n",
    "    return Result(value=result)\n",
    "\n",
    "content_sequencer_agent = Agent(\n",
    "    name=\"ContentSequencer\",\n",
    "    instructions=\"\"\"You determine what content to teach next based on student progress.\n",
    "Use student memory to avoid repetition and focus on knowledge gaps.\n",
    "Apply learned sequencing strategies from past successful sessions.\"\"\",\n",
    "    functions=[get_next_content]\n",
    ")\n",
    "\n",
    "def analyze_student_emotion(context_variables: Dict):\n",
    "    \"\"\"\n",
    "    Emotion Analyzer agent - provides deep emotional insights\n",
    "    \"\"\"\n",
    "    student_message = context_variables.get(\"student_message\", \"\")\n",
    "    emotion_data = detect_emotion(student_message)\n",
    "    \n",
    "    # Query appropriate teaching style\n",
    "    teaching_style = query_teaching_style(emotion_data[\"dominant\"])\n",
    "    \n",
    "    # Get past successful emotional handling strategies\n",
    "    past_strategies = learning_system.retrieve_successful_strategies(\n",
    "        agent_name=\"emotion_analyzer\",\n",
    "        situation=f\"Student showing {emotion_data['dominant']} emotion\",\n",
    "        top_k=2\n",
    "    )\n",
    "    \n",
    "    strategy_guidance = \"\"\n",
    "    if past_strategies:\n",
    "        strategy_guidance = f\"\\nProven approach: {past_strategies[0]['action']}\"\n",
    "    \n",
    "    analysis = f\"\"\"Emotional Analysis:\n",
    "Dominant emotion: {emotion_data['dominant']}\n",
    "All scores: {emotion_data['scores']}\n",
    "\n",
    "Recommended teaching style: {teaching_style['name']}\n",
    "Style characteristics: {teaching_style.get('characteristics', 'Standard approach')}\n",
    "{strategy_guidance}\n",
    "\n",
    "Adjust tone and pacing accordingly.\"\"\"\n",
    "    \n",
    "    # Store emotion handling experience\n",
    "    learning_system.store_experience(\n",
    "        agent_name=\"emotion_analyzer\",\n",
    "        situation=f\"Detected {emotion_data['dominant']} emotion\",\n",
    "        action=f\"Applied {teaching_style['name']} teaching style\",\n",
    "        outcome_score=0.75,\n",
    "        metadata={\"emotion\": emotion_data['dominant'], \"style\": teaching_style['name']}\n",
    "    )\n",
    "    \n",
    "    return Result(value=analysis)\n",
    "\n",
    "emotion_analyzer_agent = Agent(\n",
    "    name=\"EmotionAnalyzer\",\n",
    "    instructions=\"\"\"You analyze student emotions and recommend appropriate teaching approaches.\n",
    "Detect frustration, confusion, confidence, and adjust teaching style accordingly.\n",
    "Learn from past successful emotional interventions.\"\"\",\n",
    "    functions=[analyze_student_emotion]\n",
    ")\n",
    "\n",
    "def adapt_teaching_style(context_variables: Dict):\n",
    "    \"\"\"\n",
    "    Style Adapter agent - modifies content delivery style\n",
    "    \"\"\"\n",
    "    current_emotion = agent_context.get(\"current_emotion\", \"neutral\")\n",
    "    current_topic = agent_context.get(\"current_topic\", \"general\")\n",
    "    \n",
    "    # Get past successful style adaptations\n",
    "    past_strategies = learning_system.retrieve_successful_strategies(\n",
    "        agent_name=\"style_adapter\",\n",
    "        situation=f\"Teaching {current_topic} to student feeling {current_emotion}\",\n",
    "        top_k=2\n",
    "    )\n",
    "    \n",
    "    teaching_style = query_teaching_style(current_emotion)\n",
    "    \n",
    "    adaptation = f\"\"\"Style Adaptation for {current_emotion} student:\n",
    "\n",
    "Teaching style: {teaching_style['name']}\n",
    "Approach: {teaching_style.get('description', 'Balanced approach')}\n",
    "\n",
    "Delivery modifications:\n",
    "- Tone: {'Encouraging and supportive' if current_emotion in ['fear', 'sadness'] else 'Enthusiastic and engaging'}\n",
    "- Pace: {'Slower with more examples' if current_emotion == 'fear' else 'Moderate'}\n",
    "- Complexity: {'Simplified concepts first' if current_emotion == 'fear' else 'Progressive complexity'}\n",
    "\"\"\"\n",
    "    \n",
    "    if past_strategies:\n",
    "        adaptation += f\"\\nLearned from past: {past_strategies[0]['action']}\"\n",
    "    \n",
    "    # Store adaptation decision\n",
    "    learning_system.store_experience(\n",
    "        agent_name=\"style_adapter\",\n",
    "        situation=f\"Adapted style for {current_emotion} emotion\",\n",
    "        action=f\"Used {teaching_style['name']} approach\",\n",
    "        outcome_score=0.8,\n",
    "        metadata={\"emotion\": current_emotion, \"style\": teaching_style['name']}\n",
    "    )\n",
    "    \n",
    "    return Result(value=adaptation)\n",
    "\n",
    "style_adapter_agent = Agent(\n",
    "    name=\"StyleAdapter\",\n",
    "    instructions=\"\"\"You modify teaching delivery style based on student's emotional state.\n",
    "Adapt tone, pacing, complexity, and examples to match student needs.\n",
    "Apply successful adaptation strategies from agent learning system.\"\"\",\n",
    "    functions=[adapt_teaching_style]\n",
    ")\n",
    "\n",
    "def explain_concept(context_variables: Dict):\n",
    "    \"\"\"\n",
    "    Explainer agent - provides detailed explanations with examples\n",
    "    \"\"\"\n",
    "    concept = context_variables.get(\"concept\", \"\")\n",
    "    difficulty_level = context_variables.get(\"difficulty\", \"beginner\")\n",
    "    \n",
    "    # Use Groq for detailed explanation\n",
    "    try:\n",
    "        response = groq_client.chat.completions.create(\n",
    "            model=GROQ_MODEL,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"\"\"You are an expert teacher explaining concepts at {difficulty_level} level.\n",
    "Provide clear explanations with practical examples.\n",
    "Break down complex ideas into understandable parts.\"\"\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Explain this concept clearly: {concept}\"\n",
    "                }\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=500\n",
    "        )\n",
    "        \n",
    "        explanation = response.choices[0].message.content\n",
    "        \n",
    "        # Store successful explanation\n",
    "        learning_system.store_experience(\n",
    "            agent_name=\"explainer\",\n",
    "            situation=f\"Explained {concept} at {difficulty_level} level\",\n",
    "            action=f\"Generated detailed explanation\",\n",
    "            outcome_score=0.85,\n",
    "            metadata={\"concept\": concept, \"difficulty\": difficulty_level}\n",
    "        )\n",
    "        \n",
    "        return Result(value=explanation)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return Result(value=f\"Could not generate explanation: {str(e)}\")\n",
    "\n",
    "explainer_agent = Agent(\n",
    "    name=\"Explainer\",\n",
    "    instructions=\"\"\"You provide detailed, clear explanations of concepts.\n",
    "Use analogies, examples, and step-by-step breakdowns.\n",
    "Adapt explanation depth to student's current understanding level.\"\"\",\n",
    "    functions=[explain_concept]\n",
    ")\n",
    "\n",
    "def manage_student_memory(context_variables: Dict):\n",
    "    \"\"\"\n",
    "    Memory Manager agent - tracks and updates student progress\n",
    "    \"\"\"\n",
    "    student_id = context_variables.get(\"student_id\")\n",
    "    action = context_variables.get(\"action\", \"get_profile\")\n",
    "    \n",
    "    if action == \"get_profile\":\n",
    "        profile = memory_system.get_student_profile(student_id)\n",
    "        if profile:\n",
    "            return Result(value=f\"\"\"Student Profile:\n",
    "Topics covered: {len(profile.get('topics_covered', []))}\n",
    "Mastered topics: {profile.get('mastered_topics', [])}\n",
    "Confusion points: {profile.get('confusion_points', [])}\n",
    "Total interactions: {profile.get('total_interactions', 0)}\n",
    "Last emotion: {profile.get('last_emotion', 'N/A')}\"\"\")\n",
    "        else:\n",
    "            return Result(value=\"Student not found. Initializing new student.\")\n",
    "    \n",
    "    elif action == \"update_progress\":\n",
    "        topic = context_variables.get(\"topic\")\n",
    "        understood = context_variables.get(\"understood\", True)\n",
    "        emotion = context_variables.get(\"emotion\", \"neutral\")\n",
    "        style = context_variables.get(\"style\", \"Balanced\")\n",
    "        \n",
    "        memory_system.update_student_progress(student_id, topic, understood, emotion, style)\n",
    "        \n",
    "        # Store memory management action\n",
    "        learning_system.store_experience(\n",
    "            agent_name=\"memory_manager\",\n",
    "            situation=f\"Updated progress for topic: {topic}\",\n",
    "            action=f\"Recorded {'success' if understood else 'confusion'}\",\n",
    "            outcome_score=1.0 if understood else 0.5,\n",
    "            metadata={\"topic\": topic, \"understood\": understood}\n",
    "        )\n",
    "        \n",
    "        return Result(value=f\"Progress updated for {student_id}\")\n",
    "    \n",
    "    return Result(value=\"Unknown memory action\")\n",
    "\n",
    "memory_manager_agent = Agent(\n",
    "    name=\"MemoryManager\",\n",
    "    instructions=\"\"\"You track student learning progress and preferences.\n",
    "Update student profiles after each interaction.\n",
    "Identify patterns in learning behavior for better recommendations.\"\"\",\n",
    "    functions=[manage_student_memory]\n",
    ")\n",
    "\n",
    "print(\"All 6 agents initialized successfully\")\n",
    "print(\"Agents: Orchestrator, Content Sequencer, Emotion Analyzer, Style Adapter, Explainer, Memory Manager\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f6bb0",
   "metadata": {},
   "source": [
    "## Step 13: Adaptive Tutoring Session\n",
    "\n",
    "Basic teaching session that uses all agents collaboratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acded075",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveTutoringSession:\n",
    "    \"\"\"\n",
    "    Main teaching session orchestrating all agents\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, student_id: str):\n",
    "        self.student_id = student_id\n",
    "        self.client = Swarm()\n",
    "        self.session_log = []\n",
    "        self.session_start = datetime.now()\n",
    "        \n",
    "        # Initialize student if needed\n",
    "        profile = memory_system.get_student_profile(student_id)\n",
    "        if not profile:\n",
    "            memory_system.initialize_student(student_id)\n",
    "            print(f\"New student initialized: {student_id}\")\n",
    "        \n",
    "        # Set up agent context\n",
    "        agent_context[\"current_student\"] = student_id\n",
    "    \n",
    "    def start_session(self, initial_message: str = \"I'm ready to learn\"):\n",
    "        \"\"\"Begin a teaching session\"\"\"\n",
    "        print(f\"\\n=== Starting Adaptive Tutoring Session for {self.student_id} ===\\n\")\n",
    "        \n",
    "        context = {\n",
    "            \"student_id\": self.student_id,\n",
    "            \"student_message\": initial_message\n",
    "        }\n",
    "        \n",
    "        # Run orchestrator\n",
    "        response = self.client.run(\n",
    "            agent=orchestrator_agent,\n",
    "            messages=[{\"role\": \"user\", \"content\": initial_message}],\n",
    "            context_variables=context\n",
    "        )\n",
    "        \n",
    "        self.session_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"action\": \"session_start\",\n",
    "            \"message\": initial_message,\n",
    "            \"response\": response.messages[-1][\"content\"] if response.messages else \"No response\"\n",
    "        })\n",
    "        \n",
    "        return response.messages[-1][\"content\"] if response.messages else \"Session initialized\"\n",
    "    \n",
    "    def get_next_lesson(self):\n",
    "        \"\"\"Get next content to teach\"\"\"\n",
    "        print(f\"\\nFetching next lesson for {self.student_id}...\")\n",
    "        \n",
    "        context = {\"student_id\": self.student_id}\n",
    "        \n",
    "        response = self.client.run(\n",
    "            agent=content_sequencer_agent,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"What should I learn next?\"}],\n",
    "            context_variables=context\n",
    "        )\n",
    "        \n",
    "        content = response.messages[-1][\"content\"] if response.messages else \"No content available\"\n",
    "        \n",
    "        self.session_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"action\": \"get_next_lesson\",\n",
    "            \"content\": content\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{content}\")\n",
    "        return content\n",
    "    \n",
    "    def student_response(self, message: str):\n",
    "        \"\"\"Process student response during teaching\"\"\"\n",
    "        print(f\"\\nStudent: {message}\")\n",
    "        \n",
    "        # Detect emotion\n",
    "        emotion = detect_emotion(message)\n",
    "        print(f\"Detected emotion: {emotion['dominant']}\")\n",
    "        \n",
    "        context = {\n",
    "            \"student_id\": self.student_id,\n",
    "            \"student_message\": message\n",
    "        }\n",
    "        \n",
    "        # Analyze emotion\n",
    "        emotion_response = self.client.run(\n",
    "            agent=emotion_analyzer_agent,\n",
    "            messages=[{\"role\": \"user\", \"content\": message}],\n",
    "            context_variables=context\n",
    "        )\n",
    "        \n",
    "        emotion_analysis = emotion_response.messages[-1][\"content\"] if emotion_response.messages else \"\"\n",
    "        print(f\"\\nEmotion Analysis:\\n{emotion_analysis}\")\n",
    "        \n",
    "        # Adapt style\n",
    "        style_response = self.client.run(\n",
    "            agent=style_adapter_agent,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"How should I adapt my teaching?\"}],\n",
    "            context_variables=context\n",
    "        )\n",
    "        \n",
    "        style_adaptation = style_response.messages[-1][\"content\"] if style_response.messages else \"\"\n",
    "        print(f\"\\nStyle Adaptation:\\n{style_adaptation}\")\n",
    "        \n",
    "        self.session_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"action\": \"student_response\",\n",
    "            \"message\": message,\n",
    "            \"emotion\": emotion,\n",
    "            \"emotion_analysis\": emotion_analysis,\n",
    "            \"style_adaptation\": style_adaptation\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"emotion\": emotion,\n",
    "            \"analysis\": emotion_analysis,\n",
    "            \"adaptation\": style_adaptation\n",
    "        }\n",
    "    \n",
    "    def explain(self, concept: str):\n",
    "        \"\"\"Get detailed explanation of concept\"\"\"\n",
    "        print(f\"\\nExplaining: {concept}\")\n",
    "        \n",
    "        context = {\n",
    "            \"concept\": concept,\n",
    "            \"difficulty\": \"intermediate\"\n",
    "        }\n",
    "        \n",
    "        response = self.client.run(\n",
    "            agent=explainer_agent,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Explain: {concept}\"}],\n",
    "            context_variables=context\n",
    "        )\n",
    "        \n",
    "        explanation = response.messages[-1][\"content\"] if response.messages else \"No explanation available\"\n",
    "        \n",
    "        print(f\"\\n{explanation}\")\n",
    "        \n",
    "        self.session_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"action\": \"explain\",\n",
    "            \"concept\": concept,\n",
    "            \"explanation\": explanation\n",
    "        })\n",
    "        \n",
    "        return explanation\n",
    "    \n",
    "    def update_progress(self, topic: str, understood: bool):\n",
    "        \"\"\"Update student progress after teaching a topic\"\"\"\n",
    "        current_emotion = agent_context.get(\"current_emotion\", \"neutral\")\n",
    "        \n",
    "        context = {\n",
    "            \"student_id\": self.student_id,\n",
    "            \"action\": \"update_progress\",\n",
    "            \"topic\": topic,\n",
    "            \"understood\": understood,\n",
    "            \"emotion\": current_emotion,\n",
    "            \"style\": \"Adaptive\"\n",
    "        }\n",
    "        \n",
    "        response = self.client.run(\n",
    "            agent=memory_manager_agent,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Update progress for {topic}\"}],\n",
    "            context_variables=context\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nProgress updated: {topic} - {'Mastered' if understood else 'Needs review'}\")\n",
    "        \n",
    "        self.session_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"action\": \"update_progress\",\n",
    "            \"topic\": topic,\n",
    "            \"understood\": understood\n",
    "        })\n",
    "    \n",
    "    def end_session(self):\n",
    "        \"\"\"End teaching session and generate report\"\"\"\n",
    "        session_duration = (datetime.now() - self.session_start).total_seconds()\n",
    "        \n",
    "        # Get final student profile\n",
    "        profile = memory_system.get_student_profile(self.student_id)\n",
    "        \n",
    "        report = {\n",
    "            \"student_id\": self.student_id,\n",
    "            \"session_duration_seconds\": session_duration,\n",
    "            \"total_interactions\": len(self.session_log),\n",
    "            \"topics_covered\": len([log for log in self.session_log if log.get(\"action\") == \"get_next_lesson\"]),\n",
    "            \"student_profile\": profile,\n",
    "            \"session_log\": self.session_log\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n=== Session Complete ===\")\n",
    "        print(f\"Duration: {session_duration:.1f} seconds\")\n",
    "        print(f\"Interactions: {len(self.session_log)}\")\n",
    "        print(f\"Topics covered: {report['topics_covered']}\")\n",
    "        \n",
    "        return report\n",
    "\n",
    "print(\"Adaptive Tutoring Session class ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feab46c",
   "metadata": {},
   "source": [
    "## Step 14: Intelligent Lesson Planner\n",
    "\n",
    "PHASE 1: PDF  Generate Lesson Plan  Iterate  Approve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelligentLessonPlanner:\n",
    "    \"\"\"\n",
    "    Phase 1: Generate and iterate on lesson plans before teaching begins\n",
    "    Human-in-the-loop lesson planning\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.current_plan = None\n",
    "        self.iteration_history = []\n",
    "    \n",
    "    def analyze_pdf_content(self, sample_size: int = 200) -> Dict:\n",
    "        \"\"\"\n",
    "        Analyze all ingested PDF content to extract actual structure and topics\n",
    "        \"\"\"\n",
    "        print(\"\\nAnalyzing PDF content structure...\")\n",
    "        \n",
    "        # Get content from Qdrant\n",
    "        results = qdrant_client.scroll(\n",
    "            collection_name=COLLECTION_PDF_CONTENT,\n",
    "            limit=sample_size\n",
    "        )\n",
    "        \n",
    "        if not results[0]:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": \"No PDF content found. Please upload a PDF first.\"\n",
    "            }\n",
    "        \n",
    "        all_content = []\n",
    "        content_samples = []\n",
    "        \n",
    "        for point in results[0]:\n",
    "            payload = point.payload\n",
    "            all_content.append({\n",
    "                \"sequence_id\": payload.get(\"sequence_id\"),\n",
    "                \"text\": payload.get(\"text\", \"\"),\n",
    "                \"page\": payload.get(\"page\"),\n",
    "                \"difficulty\": payload.get(\"difficulty\", \"intermediate\")\n",
    "            })\n",
    "            \n",
    "            # Collect samples for chapter detection\n",
    "            if len(content_samples) < 50:\n",
    "                content_samples.append(payload.get(\"text\", \"\")[:300])\n",
    "        \n",
    "        # Combine samples for LLM analysis\n",
    "        combined_samples = \"\\n\\n---\\n\\n\".join(content_samples[:20])\n",
    "        \n",
    "        analysis = {\n",
    "            \"total_sections\": len(all_content),\n",
    "            \"difficulty_levels\": list(set(item[\"difficulty\"] for item in all_content)),\n",
    "            \"content_preview\": all_content[:10],\n",
    "            \"content_samples\": combined_samples\n",
    "        }\n",
    "        \n",
    "        print(f\"Found {len(all_content)} content sections\")\n",
    "        print(f\"Extracted samples from first 20 sections for analysis\")\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    def generate_lesson_plan(self, learning_objectives: str = None, \n",
    "                           target_duration: int = 60,\n",
    "                           difficulty_preference: str = \"progressive\") -> Dict:\n",
    "        \"\"\"\n",
    "        Generate initial lesson plan using Groq LLM\n",
    "        \"\"\"\n",
    "        print(f\"\\nGenerating lesson plan...\")\n",
    "        print(f\"Duration: {target_duration} minutes\")\n",
    "        print(f\"Difficulty: {difficulty_preference}\")\n",
    "        \n",
    "        # Analyze PDF content\n",
    "        content_analysis = self.analyze_pdf_content()\n",
    "        \n",
    "        if content_analysis.get(\"status\") == \"error\":\n",
    "            return content_analysis\n",
    "        \n",
    "        # Create prompt for Groq\n",
    "        prompt = f\"\"\"You are analyzing a PDF document to create a detailed teaching curriculum.\n",
    "\n",
    "ACTUAL PDF CONTENT SAMPLES:\n",
    "{content_analysis['content_samples']}\n",
    "\n",
    "Based on the actual content above, create a DETAILED lesson plan that follows the PDF structure.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Identify actual chapters/sections from the PDF content\n",
    "2. For EACH major topic, create lessons with subsections (1, 1.1, 1.2, etc.)\n",
    "3. After EACH major lesson, include a quiz checkpoint\n",
    "4. Extract real topic names from the PDF (not generic names)\n",
    "5. Total available sections: {content_analysis['total_sections']}\n",
    "\n",
    "Requirements:\n",
    "- Target duration: {target_duration} minutes per major lesson\n",
    "- Create lessons for at least 8-10 major topics from the PDF\n",
    "- Each lesson should have 2-5 subsections\n",
    "- Include quiz after each major lesson\n",
    "\n",
    "Output JSON format:\n",
    "{{\n",
    "  \"learningObjectives\": [\"objective1\", \"objective2\", ...],\n",
    "  \"lessons\": [\n",
    "    {{\n",
    "      \"lessonNumber\": 1,\n",
    "      \"title\": \"Actual Chapter Title from PDF\",\n",
    "      \"duration\": 15,\n",
    "      \"subsections\": [\n",
    "        {{\"number\": \"1.1\", \"title\": \"Subsection from PDF\", \"sequenceStart\": 0, \"sequenceEnd\": 10}},\n",
    "        {{\"number\": \"1.2\", \"title\": \"Next subsection\", \"sequenceStart\": 11, \"sequenceEnd\": 20}}\n",
    "      ],\n",
    "      \"teachingStrategy\": \"How to teach this\",\n",
    "      \"quizAfter\": true\n",
    "    }},\n",
    "    {{\n",
    "      \"lessonNumber\": 2,\n",
    "      \"title\": \"Next Chapter Title\",\n",
    "      ...\n",
    "    }}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "IMPORTANT: Base everything on the ACTUAL PDF content shown above, not generic topics.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = groq_client.chat.completions.create(\n",
    "                model=GROQ_MODEL,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You are an expert curriculum designer creating structured lesson plans. Output valid JSON only.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0.8,\n",
    "                max_tokens=2000\n",
    "            )\n",
    "            \n",
    "            plan_text = response.choices[0].message.content\n",
    "            \n",
    "            # Extract JSON from markdown code blocks if present\n",
    "            import re\n",
    "            json_match = re.search(r'```(?:json)?\\s*(\\{.*?\\})\\s*```', plan_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                plan_text = json_match.group(1)\n",
    "            \n",
    "            # Try to parse as JSON, fallback to text\n",
    "            try:\n",
    "                plan_data = json.loads(plan_text)\n",
    "            except Exception as parse_error:\n",
    "                plan_data = {\n",
    "                    \"plan_text\": plan_text,\n",
    "                    \"structured\": False,\n",
    "                    \"parse_error\": str(parse_error)\n",
    "                }\n",
    "            \n",
    "            self.current_plan = {\n",
    "                \"version\": 1,\n",
    "                \"created_at\": datetime.now().isoformat(),\n",
    "                \"parameters\": {\n",
    "                    \"learning_objectives\": learning_objectives,\n",
    "                    \"target_duration\": target_duration,\n",
    "                    \"difficulty_preference\": difficulty_preference\n",
    "                },\n",
    "                \"content_analysis\": content_analysis,\n",
    "                \"plan\": plan_data\n",
    "            }\n",
    "            \n",
    "            self.iteration_history.append({\n",
    "                \"version\": 1,\n",
    "                \"action\": \"initial_generation\",\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            print(\"\\nLesson plan generated successfully!\")\n",
    "            return self.current_plan\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": f\"Failed to generate lesson plan: {str(e)}\"\n",
    "            }\n",
    "    \n",
    "    def iterate_plan(self, feedback: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Refine lesson plan based on human feedback\n",
    "        Human-in-the-loop iteration\n",
    "        \"\"\"\n",
    "        if not self.current_plan:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": \"No lesson plan exists. Generate one first.\"\n",
    "            }\n",
    "        \n",
    "        print(f\"\\nIterating on lesson plan based on feedback...\")\n",
    "        print(f\"Feedback: {feedback[:100]}...\")\n",
    "        \n",
    "        current_version = self.current_plan[\"version\"]\n",
    "        \n",
    "        prompt = f\"\"\"You are refining a lesson plan based on feedback.\n",
    "\n",
    "Current Lesson Plan:\n",
    "{json.dumps(self.current_plan['plan'], indent=2)}\n",
    "\n",
    "Feedback from instructor:\n",
    "{feedback}\n",
    "\n",
    "Create an improved version that addresses the feedback while maintaining structure.\n",
    "Output as JSON with same structure as before.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = groq_client.chat.completions.create(\n",
    "                model=GROQ_MODEL,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You refine lesson plans based on feedback. Output valid JSON only.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=2000\n",
    "            )\n",
    "            \n",
    "            refined_plan_text = response.choices[0].message.content\n",
    "            \n",
    "            # Extract JSON from markdown code blocks if present\n",
    "            import re\n",
    "            json_match = re.search(r'```(?:json)?\\s*(\\{.*?\\})\\s*```', refined_plan_text, re.DOTALL)\n",
    "            if json_match:\n",
    "                refined_plan_text = json_match.group(1)\n",
    "            \n",
    "            try:\n",
    "                import json\n",
    "                refined_plan = json.loads(refined_plan_text)\n",
    "            except Exception as parse_error:\n",
    "                refined_plan = {\n",
    "                    \"plan_text\": refined_plan_text,\n",
    "                    \"structured\": False,\n",
    "                    \"parse_error\": str(parse_error)\n",
    "                }\n",
    "            \n",
    "            self.current_plan[\"version\"] = current_version + 1\n",
    "            self.current_plan[\"plan\"] = refined_plan\n",
    "            self.current_plan[\"last_updated\"] = datetime.now().isoformat()\n",
    "            \n",
    "            self.iteration_history.append({\n",
    "                \"version\": current_version + 1,\n",
    "                \"action\": \"iteration\",\n",
    "                \"feedback\": feedback,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            })\n",
    "            \n",
    "            print(f\"\\nLesson plan updated to version {self.current_plan['version']}\")\n",
    "            return self.current_plan\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": f\"Failed to iterate plan: {str(e)}\"\n",
    "            }\n",
    "    \n",
    "    def approve_plan(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Finalize and approve lesson plan\n",
    "        Marks plan as ready for teaching\n",
    "        \"\"\"\n",
    "        if not self.current_plan:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": \"No lesson plan to approve\"\n",
    "            }\n",
    "        \n",
    "        self.current_plan[\"approved\"] = True\n",
    "        self.current_plan[\"approved_at\"] = datetime.now().isoformat()\n",
    "        self.current_plan[\"final_version\"] = self.current_plan[\"version\"]\n",
    "        \n",
    "        self.iteration_history.append({\n",
    "            \"version\": self.current_plan[\"version\"],\n",
    "            \"action\": \"approval\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        print(\"\\nLesson plan APPROVED and ready for teaching!\")\n",
    "        print(f\"Final version: {self.current_plan['version']}\")\n",
    "        print(f\"Total iterations: {len(self.iteration_history)}\")\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"approved\",\n",
    "            \"plan\": self.current_plan,\n",
    "            \"iteration_count\": len(self.iteration_history)\n",
    "        }\n",
    "    \n",
    "    def get_current_plan(self) -> Dict:\n",
    "        \"\"\"Get current lesson plan\"\"\"\n",
    "        return self.current_plan\n",
    "    \n",
    "    def get_iteration_history(self) -> List[Dict]:\n",
    "        \"\"\"Get history of all iterations\"\"\"\n",
    "        return self.iteration_history\n",
    "\n",
    "planner = IntelligentLessonPlanner()\n",
    "print(\"Intelligent Lesson Planner ready\")\n",
    "print(\"Workflow: generate_lesson_plan() to  iterate_plan(feedback) to approve_plan()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf93fbb",
   "metadata": {},
   "source": [
    "## Step 15: Quiz System\n",
    "\n",
    "Generate adaptive quizzes to assess understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37958db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuizSystem:\n",
    "    \"\"\"\n",
    "    Generate and evaluate quizzes based on taught content\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.quiz_history = []\n",
    "    \n",
    "    def generate_quiz(self, topic: str, difficulty: str = \"intermediate\", \n",
    "                     num_questions: int = 3) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate quiz questions using Groq LLM\n",
    "        \"\"\"\n",
    "        print(f\"\\nGenerating quiz: {topic} ({difficulty})\")\n",
    "        print(f\"Questions: {num_questions}\")\n",
    "        \n",
    "        # Get related content from PDF\n",
    "        content = query_pdf_content(topic_search=topic, difficulty=difficulty)\n",
    "        \n",
    "        prompt = f\"\"\"Generate {num_questions} multiple choice questions to test understanding.\n",
    "\n",
    "Topic: {topic}\n",
    "Difficulty: {difficulty}\n",
    "Content context: {content.get('text', '')[:500]}\n",
    "\n",
    "For each question provide:\n",
    "1. Question text\n",
    "2. 4 answer options (A, B, C, D)\n",
    "3. Correct answer (letter)\n",
    "4. Explanation of why that's correct\n",
    "\n",
    "Format as JSON array of questions.\"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = groq_client.chat.completions.create(\n",
    "                model=GROQ_MODEL,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"You create educational quiz questions. Output valid JSON only.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": prompt\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_tokens=1500\n",
    "            )\n",
    "            \n",
    "            quiz_text = response.choices[0].message.content\n",
    "            \n",
    "            try:\n",
    "                import json\n",
    "                questions = json.loads(quiz_text)\n",
    "            except:\n",
    "                questions = {\n",
    "                    \"questions\": [\n",
    "                        {\n",
    "                            \"question\": \"Sample question about \" + topic,\n",
    "                            \"options\": [\"A: Option 1\", \"B: Option 2\", \"C: Option 3\", \"D: Option 4\"],\n",
    "                            \"correct\": \"A\",\n",
    "                            \"explanation\": \"This is a fallback question\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"parse_error\": True\n",
    "                }\n",
    "            \n",
    "            quiz = {\n",
    "                \"quiz_id\": str(uuid.uuid4()),\n",
    "                \"topic\": topic,\n",
    "                \"difficulty\": difficulty,\n",
    "                \"num_questions\": num_questions,\n",
    "                \"questions\": questions if isinstance(questions, list) else questions.get(\"questions\", []),\n",
    "                \"created_at\": datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            self.quiz_history.append(quiz)\n",
    "            \n",
    "            print(f\"\\nQuiz generated with ID: {quiz['quiz_id'][:8]}\")\n",
    "            return quiz\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": f\"Failed to generate quiz: {str(e)}\"\n",
    "            }\n",
    "    \n",
    "    def evaluate_answers(self, quiz_id: str, student_answers: Dict[int, str]) -> Dict:\n",
    "        \"\"\"\n",
    "        Evaluate student's quiz answers\n",
    "        \n",
    "        Args:\n",
    "            quiz_id: ID of the quiz\n",
    "            student_answers: Dict mapping question index to student's answer (e.g., {0: \"A\", 1: \"B\"})\n",
    "        \"\"\"\n",
    "        # Find quiz\n",
    "        quiz = None\n",
    "        for q in self.quiz_history:\n",
    "            if q[\"quiz_id\"] == quiz_id:\n",
    "                quiz = q\n",
    "                break\n",
    "        \n",
    "        if not quiz:\n",
    "            return {\n",
    "                \"status\": \"error\",\n",
    "                \"message\": \"Quiz not found\"\n",
    "            }\n",
    "        \n",
    "        questions = quiz[\"questions\"]\n",
    "        results = []\n",
    "        correct_count = 0\n",
    "        \n",
    "        for idx, student_answer in student_answers.items():\n",
    "            if idx >= len(questions):\n",
    "                continue\n",
    "            \n",
    "            question = questions[idx]\n",
    "            correct_answer = question.get(\"correct\", \"\").upper()\n",
    "            student_answer_clean = student_answer.upper().strip()\n",
    "            \n",
    "            is_correct = student_answer_clean == correct_answer\n",
    "            \n",
    "            if is_correct:\n",
    "                correct_count += 1\n",
    "            \n",
    "            results.append({\n",
    "                \"question_index\": idx,\n",
    "                \"question\": question.get(\"question\"),\n",
    "                \"student_answer\": student_answer,\n",
    "                \"correct_answer\": correct_answer,\n",
    "                \"is_correct\": is_correct,\n",
    "                \"explanation\": question.get(\"explanation\", \"\")\n",
    "            })\n",
    "        \n",
    "        total_questions = len(student_answers)\n",
    "        score_percentage = (correct_count / total_questions * 100) if total_questions > 0 else 0\n",
    "        \n",
    "        evaluation = {\n",
    "            \"quiz_id\": quiz_id,\n",
    "            \"topic\": quiz[\"topic\"],\n",
    "            \"total_questions\": total_questions,\n",
    "            \"correct_answers\": correct_count,\n",
    "            \"score_percentage\": score_percentage,\n",
    "            \"passed\": score_percentage >= 70,\n",
    "            \"results\": results,\n",
    "            \"evaluated_at\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nQuiz Results:\")\n",
    "        print(f\"Score: {correct_count}/{total_questions} ({score_percentage:.1f}%)\")\n",
    "        print(f\"Status: {'PASSED' if evaluation['passed'] else 'NEEDS REVIEW'}\")\n",
    "        \n",
    "        return evaluation\n",
    "    \n",
    "    def get_quiz_by_id(self, quiz_id: str) -> Dict:\n",
    "        \"\"\"Retrieve quiz by ID\"\"\"\n",
    "        for quiz in self.quiz_history:\n",
    "            if quiz[\"quiz_id\"] == quiz_id:\n",
    "                return quiz\n",
    "        return None\n",
    "\n",
    "quiz_system = QuizSystem()\n",
    "print(\"Quiz System initialized\")\n",
    "print(\"Can generate adaptive quizzes and evaluate answers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63de13ef",
   "metadata": {},
   "source": [
    "## Step 16: Enhanced Teaching Session V2\n",
    "\n",
    "Complete teaching session with whiteboard and quiz integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b07efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveTutoringSessionV2:\n",
    "    \"\"\"\n",
    "    Enhanced teaching session with whiteboard images and quiz checkpoints\n",
    "    Full-featured teaching experience\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, student_id: str, lesson_plan: Dict = None):\n",
    "        self.student_id = student_id\n",
    "        self.lesson_plan = lesson_plan\n",
    "        self.client = Swarm()\n",
    "        self.session_log = []\n",
    "        self.session_start = datetime.now()\n",
    "        self.current_topic = None\n",
    "        self.whiteboard_images = []\n",
    "        self.quiz_results = []\n",
    "        \n",
    "        # Initialize student\n",
    "        profile = memory_system.get_student_profile(student_id)\n",
    "        if not profile:\n",
    "            memory_system.initialize_student(student_id)\n",
    "            print(f\"New student initialized: {student_id}\")\n",
    "        \n",
    "        agent_context[\"current_student\"] = student_id\n",
    "        \n",
    "        print(f\"\\n=== Enhanced Adaptive Tutoring Session ===\")\n",
    "        print(f\"Student: {student_id}\")\n",
    "        if lesson_plan:\n",
    "            print(f\"Following approved lesson plan v{lesson_plan.get('version')}\")\n",
    "    \n",
    "    def teach_topic(self, topic: str, sequence_id: int = None):\n",
    "        \"\"\"\n",
    "        Teach a specific topic with full adaptive features\n",
    "        \"\"\"\n",
    "        print(f\"\\n--- Teaching Topic: {topic} ---\")\n",
    "        self.current_topic = topic\n",
    "        agent_context[\"current_topic\"] = topic\n",
    "        \n",
    "        # Get content\n",
    "        content = query_pdf_content(sequence_id=sequence_id, topic_search=topic)\n",
    "        \n",
    "        print(f\"\\nContent: {content.get('text', 'No content')[:300]}...\")\n",
    "        \n",
    "        # Get whiteboard images if available\n",
    "        if content.get(\"page\"):\n",
    "            images = query_related_images(content[\"page\"])\n",
    "            if images:\n",
    "                print(f\"\\nWhiteboard: {len(images)} visual aids available\")\n",
    "                self.whiteboard_images.extend(images)\n",
    "        \n",
    "        self.session_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"action\": \"teach_topic\",\n",
    "            \"topic\": topic,\n",
    "            \"content\": content.get(\"text\", \"\")[:500]\n",
    "        })\n",
    "        \n",
    "        return content\n",
    "    \n",
    "    def process_student_input(self, message: str):\n",
    "        \"\"\"\n",
    "        Process student message with full emotion and style adaptation\n",
    "        \"\"\"\n",
    "        print(f\"\\nStudent: {message}\")\n",
    "        \n",
    "        # Emotion detection\n",
    "        emotion = detect_emotion(message)\n",
    "        print(f\"Emotion detected: {emotion['dominant']}\")\n",
    "        \n",
    "        context = {\n",
    "            \"student_id\": self.student_id,\n",
    "            \"student_message\": message\n",
    "        }\n",
    "        \n",
    "        # Get emotion analysis\n",
    "        emotion_response = self.client.run(\n",
    "            agent=emotion_analyzer_agent,\n",
    "            messages=[{\"role\": \"user\", \"content\": message}],\n",
    "            context_variables=context\n",
    "        )\n",
    "        \n",
    "        # Adapt teaching style\n",
    "        style_response = self.client.run(\n",
    "            agent=style_adapter_agent,\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Adapt teaching style\"}],\n",
    "            context_variables=context\n",
    "        )\n",
    "        \n",
    "        # Generate response\n",
    "        response_context = {\n",
    "            \"concept\": self.current_topic or \"current topic\",\n",
    "            \"difficulty\": \"intermediate\"\n",
    "        }\n",
    "        \n",
    "        explanation_response = self.client.run(\n",
    "            agent=explainer_agent,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Respond to: {message}\"}],\n",
    "            context_variables=response_context\n",
    "        )\n",
    "        \n",
    "        response_text = explanation_response.messages[-1][\"content\"] if explanation_response.messages else \"I understand your question.\"\n",
    "        \n",
    "        print(f\"\\nTeacher: {response_text[:200]}...\")\n",
    "        \n",
    "        self.session_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"action\": \"student_interaction\",\n",
    "            \"student_message\": message,\n",
    "            \"emotion\": emotion,\n",
    "            \"teacher_response\": response_text\n",
    "        })\n",
    "        \n",
    "        return {\n",
    "            \"emotion\": emotion,\n",
    "            \"response\": response_text\n",
    "        }\n",
    "    \n",
    "    def checkpoint_quiz(self, topic: str, num_questions: int = 3):\n",
    "        \"\"\"\n",
    "        Administer checkpoint quiz\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== Quiz Checkpoint: {topic} ===\")\n",
    "        \n",
    "        # Generate quiz\n",
    "        quiz = quiz_system.generate_quiz(topic, difficulty=\"intermediate\", num_questions=num_questions)\n",
    "        \n",
    "        if quiz.get(\"status\") == \"error\":\n",
    "            print(f\"Quiz generation failed: {quiz.get('message')}\")\n",
    "            return None\n",
    "        \n",
    "        # Display questions\n",
    "        print(\"\\nQuiz Questions:\")\n",
    "        questions = quiz.get(\"questions\", [])\n",
    "        for idx, q in enumerate(questions):\n",
    "            print(f\"\\nQ{idx + 1}: {q.get('question', 'No question')}\")\n",
    "            for option in q.get(\"options\", []):\n",
    "                print(f\"  {option}\")\n",
    "        \n",
    "        self.session_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"action\": \"quiz_checkpoint\",\n",
    "            \"topic\": topic,\n",
    "            \"quiz_id\": quiz.get(\"quiz_id\")\n",
    "        })\n",
    "        \n",
    "        return quiz\n",
    "    \n",
    "    def submit_quiz_answers(self, quiz_id: str, answers: Dict[int, str]):\n",
    "        \"\"\"\n",
    "        Submit and evaluate quiz answers\n",
    "        \"\"\"\n",
    "        print(f\"\\nEvaluating quiz answers...\")\n",
    "        \n",
    "        evaluation = quiz_system.evaluate_answers(quiz_id, answers)\n",
    "        \n",
    "        if evaluation.get(\"status\") == \"error\":\n",
    "            print(f\"Evaluation failed: {evaluation.get('message')}\")\n",
    "            return None\n",
    "        \n",
    "        # Update student progress based on quiz performance\n",
    "        passed = evaluation.get(\"passed\", False)\n",
    "        self.update_progress(evaluation[\"topic\"], understood=passed)\n",
    "        \n",
    "        self.quiz_results.append(evaluation)\n",
    "        \n",
    "        self.session_log.append({\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"action\": \"quiz_evaluated\",\n",
    "            \"quiz_id\": quiz_id,\n",
    "            \"score\": evaluation.get(\"score_percentage\"),\n",
    "            \"passed\": passed\n",
    "        })\n",
    "        \n",
    "        return evaluation\n",
    "    \n",
    "    def update_progress(self, topic: str, understood: bool):\n",
    "        \"\"\"Update student learning progress\"\"\"\n",
    "        current_emotion = agent_context.get(\"current_emotion\", \"neutral\")\n",
    "        \n",
    "        context = {\n",
    "            \"student_id\": self.student_id,\n",
    "            \"action\": \"update_progress\",\n",
    "            \"topic\": topic,\n",
    "            \"understood\": understood,\n",
    "            \"emotion\": current_emotion,\n",
    "            \"style\": \"Adaptive\"\n",
    "        }\n",
    "        \n",
    "        self.client.run(\n",
    "            agent=memory_manager_agent,\n",
    "            messages=[{\"role\": \"user\", \"content\": f\"Update progress for {topic}\"}],\n",
    "            context_variables=context\n",
    "        )\n",
    "        \n",
    "        print(f\"Progress updated: {topic} - {'Mastered' if understood else 'Needs review'}\")\n",
    "    \n",
    "    def generate_session_report(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Generate comprehensive session report\n",
    "        \"\"\"\n",
    "        session_duration = (datetime.now() - self.session_start).total_seconds()\n",
    "        \n",
    "        profile = memory_system.get_student_profile(self.student_id)\n",
    "        \n",
    "        report = {\n",
    "            \"student_id\": self.student_id,\n",
    "            \"session_start\": self.session_start.isoformat(),\n",
    "            \"session_duration_seconds\": session_duration,\n",
    "            \"lesson_plan_used\": self.lesson_plan is not None,\n",
    "            \"total_interactions\": len(self.session_log),\n",
    "            \"topics_taught\": len([log for log in self.session_log if log.get(\"action\") == \"teach_topic\"]),\n",
    "            \"quizzes_taken\": len(self.quiz_results),\n",
    "            \"average_quiz_score\": np.mean([r[\"score_percentage\"] for r in self.quiz_results]) if self.quiz_results else 0,\n",
    "            \"whiteboard_images_shown\": len(self.whiteboard_images),\n",
    "            \"student_profile\": profile,\n",
    "            \"quiz_results\": self.quiz_results,\n",
    "            \"session_log\": self.session_log\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n=== Session Report ===\")\n",
    "        print(f\"Duration: {session_duration / 60:.1f} minutes\")\n",
    "        print(f\"Topics taught: {report['topics_taught']}\")\n",
    "        print(f\"Quizzes: {report['quizzes_taken']}\")\n",
    "        if self.quiz_results:\n",
    "            print(f\"Average score: {report['average_quiz_score']:.1f}%\")\n",
    "        print(f\"Total interactions: {report['total_interactions']}\")\n",
    "        \n",
    "        # Save report to file\n",
    "        report_filename = f\"session_report_{self.student_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        with open(report_filename, 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        print(f\"\\nReport saved: {report_filename}\")\n",
    "        \n",
    "        return report\n",
    "\n",
    "print(\"Enhanced Tutoring Session V2 ready\")\n",
    "print(\"Features: Whiteboard images, quiz checkpoints, full emotion adaptation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24502331",
   "metadata": {},
   "source": [
    "## Step 17: Test PDF Processing and Improved Lesson Plan Display\n",
    "\n",
    "Testing with Rich Dad Poor Dad.pdf and displaying lesson plans in hierarchical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27150d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPLETE TEST INSTRUCTIONS - Read This First!\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"HOW TO RUN THE COMPLETE TEST\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nOption 1: Run All Cells (RECOMMENDED)\")\n",
    "print(\"  - Go to menu: Kernel > Restart & Run All\")\n",
    "print(\"  - This will initialize everything and run all tests\")\n",
    "print(\"\\nOption 2: Manual Step-by-Step\")\n",
    "print(\"  1. Run cells 3-18 to initialize all systems\")\n",
    "print(\"  2. Run cell 36 (hierarchical display function)\")\n",
    "print(\"  3. Run cells below for testing:\")\n",
    "print(\"     - Test 1: PDF Processing\")\n",
    "print(\"     - Test 2: Lesson Plan Generation\") \n",
    "print(\"     - Test 3: Display Hierarchical Plan\")\n",
    "print(\"     - Test 4: Student Session\")\n",
    "print(\"\\nCurrent PDF: Rich Dad Poor Dad.pdf\")\n",
    "print(\"Location: c:\\\\Users\\\\dhanu\\\\OneDrive\\\\Desktop\\\\last MAS\\\\\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f696ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_lesson_plan_hierarchical(lesson_plan: Dict):\n",
    "    \"\"\"\n",
    "    Display lesson plan in hierarchical format with proper numbering\n",
    "    (1, 1.1, 1.1.1, 2, 2.1, etc.)\n",
    "    \"\"\"\n",
    "    if not lesson_plan:\n",
    "        print(\"No lesson plan to display\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LESSON PLAN - HIERARCHICAL VIEW\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Basic info\n",
    "    print(f\"\\nVersion: {lesson_plan.get('version', 'N/A')}\")\n",
    "    print(f\"Created: {lesson_plan.get('created_at', 'N/A')}\")\n",
    "    if lesson_plan.get('approved'):\n",
    "        print(f\"Status: APPROVED\")\n",
    "    else:\n",
    "        print(f\"Status: DRAFT\")\n",
    "    \n",
    "    # Parameters\n",
    "    params = lesson_plan.get('parameters', {})\n",
    "    if params:\n",
    "        print(f\"\\nTarget Duration: {params.get('target_duration', 'N/A')} minutes\")\n",
    "        print(f\"Difficulty: {params.get('difficulty_preference', 'N/A')}\")\n",
    "        if params.get('learning_objectives'):\n",
    "            print(f\"Objectives: {params['learning_objectives']}\")\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    \n",
    "    # Get plan content\n",
    "    plan_content = lesson_plan.get('plan', {})\n",
    "    \n",
    "    # Handle nested lessonPlan structure\n",
    "    if isinstance(plan_content, dict) and 'lessonPlan' in plan_content:\n",
    "        plan_content = plan_content['lessonPlan']\n",
    "    \n",
    "    # If it's structured JSON, parse it\n",
    "    if isinstance(plan_content, dict):\n",
    "        # Learning objectives\n",
    "        objectives_key = None\n",
    "        for key in ['learning_objectives', 'learningObjectives', 'objectives']:\n",
    "            if key in plan_content:\n",
    "                objectives_key = key\n",
    "                break\n",
    "        \n",
    "        if objectives_key:\n",
    "            objectives = plan_content.get(objectives_key, [])\n",
    "            if objectives:\n",
    "                print(\"\\n1. LEARNING OBJECTIVES\")\n",
    "                if isinstance(objectives, list):\n",
    "                    for idx, obj in enumerate(objectives, 1):\n",
    "                        print(f\"   1.{idx} {obj}\")\n",
    "                else:\n",
    "                    print(f\"   {objectives}\")\n",
    "        \n",
    "        # Lessons structure (new format)\n",
    "        section_num = 2\n",
    "        if 'lessons' in plan_content:\n",
    "            lessons = plan_content.get('lessons', [])\n",
    "            if lessons:\n",
    "                print(f\"\\n{section_num}. LESSON STRUCTURE\")\n",
    "                for lesson in lessons:\n",
    "                    lesson_num = lesson.get('lessonNumber') or lesson.get('lesson_number', '?')\n",
    "                    title = lesson.get('title') or lesson.get('name', 'Untitled Lesson')\n",
    "                    duration = lesson.get('duration', '')\n",
    "                    \n",
    "                    print(f\"\\n   {section_num}.{lesson_num} {title}\")\n",
    "                    if duration:\n",
    "                        print(f\"        Duration: {duration} minutes\")\n",
    "                    \n",
    "                    # Subsections\n",
    "                    subsections = lesson.get('subsections', [])\n",
    "                    if subsections:\n",
    "                        for subsection in subsections:\n",
    "                            sub_num = subsection.get('number', '')\n",
    "                            sub_title = subsection.get('title', '')\n",
    "                            seq_range = \"\"\n",
    "                            if 'sequenceStart' in subsection and 'sequenceEnd' in subsection:\n",
    "                                seq_range = f\" (sections {subsection['sequenceStart']}-{subsection['sequenceEnd']})\"\n",
    "                            print(f\"        {section_num}.{lesson_num}.{sub_num.split('.')[-1] if '.' in sub_num else sub_num} {sub_title}{seq_range}\")\n",
    "                    \n",
    "                    # Teaching strategy\n",
    "                    strategy = lesson.get('teachingStrategy') or lesson.get('strategy', '')\n",
    "                    if strategy:\n",
    "                        print(f\"        Strategy: {strategy[:100]}...\")\n",
    "                    \n",
    "                    # Quiz checkpoint\n",
    "                    if lesson.get('quizAfter') or lesson.get('quiz_after'):\n",
    "                        print(f\"        >> QUIZ CHECKPOINT after this lesson\")\n",
    "                \n",
    "                section_num += 1\n",
    "        \n",
    "        # Content sequence / Topics (old format - fallback)\n",
    "        elif ('content_sequence' in plan_content or 'contentSequence' in plan_content or \n",
    "            'topics' in plan_content or 'sections' in plan_content):\n",
    "            topics = (plan_content.get('content_sequence') or \n",
    "                     plan_content.get('contentSequence') or \n",
    "                     plan_content.get('topics') or \n",
    "                     plan_content.get('sections', []))\n",
    "            \n",
    "            if topics:\n",
    "                print(f\"\\n{section_num}. CONTENT SEQUENCE\")\n",
    "                if isinstance(topics, list):\n",
    "                    for idx, topic in enumerate(topics, 1):\n",
    "                        if isinstance(topic, dict):\n",
    "                            topic_name = (topic.get('name') or topic.get('topic') or \n",
    "                                        topic.get('title') or topic.get('section', f'Topic {idx}'))\n",
    "                            duration = topic.get('duration') or topic.get('time') or topic.get('estimatedTime', '')\n",
    "                            strategy = topic.get('teachingStrategy') or topic.get('strategy', '')\n",
    "                            \n",
    "                            print(f\"   {section_num}.{idx} {topic_name}\")\n",
    "                            if duration:\n",
    "                                print(f\"        Duration: {duration}\")\n",
    "                            if strategy:\n",
    "                                print(f\"        Strategy: {strategy[:100]}...\")\n",
    "                            \n",
    "                            # Subtopics if any\n",
    "                            subtopics = topic.get('subtopics') or topic.get('content', [])\n",
    "                            if subtopics and isinstance(subtopics, list):\n",
    "                                for sub_idx, subtopic in enumerate(subtopics, 1):\n",
    "                                    if isinstance(subtopic, str):\n",
    "                                        print(f\"        {section_num}.{idx}.{sub_idx} {subtopic}\")\n",
    "                                    elif isinstance(subtopic, dict):\n",
    "                                        sub_name = subtopic.get('name') or subtopic.get('title', f'Subtopic {sub_idx}')\n",
    "                                        print(f\"        {section_num}.{idx}.{sub_idx} {sub_name}\")\n",
    "                        else:\n",
    "                            print(f\"   {section_num}.{idx} {topic}\")\n",
    "                section_num += 1\n",
    "        \n",
    "        # Teaching strategies\n",
    "        if 'teaching_strategies' in plan_content or 'strategies' in plan_content:\n",
    "            strategies = plan_content.get('teaching_strategies') or plan_content.get('strategies', [])\n",
    "            if strategies:\n",
    "                print(f\"\\n{section_num}. TEACHING STRATEGIES\")\n",
    "                if isinstance(strategies, list):\n",
    "                    for idx, strategy in enumerate(strategies, 1):\n",
    "                        if isinstance(strategy, dict):\n",
    "                            strat_name = strategy.get('name') or strategy.get('strategy', f'Strategy {idx}')\n",
    "                            strat_desc = strategy.get('description') or strategy.get('details', '')\n",
    "                            print(f\"   {section_num}.{idx} {strat_name}\")\n",
    "                            if strat_desc:\n",
    "                                print(f\"        {strat_desc}\")\n",
    "                        else:\n",
    "                            print(f\"   {section_num}.{idx} {strategy}\")\n",
    "                elif isinstance(strategies, dict):\n",
    "                    for idx, (key, value) in enumerate(strategies.items(), 1):\n",
    "                        print(f\"   {section_num}.{idx} {key}: {value}\")\n",
    "                section_num += 1\n",
    "        \n",
    "        # Assessment checkpoints\n",
    "        if 'assessment' in plan_content or 'assessments' in plan_content or 'checkpoints' in plan_content:\n",
    "            assessments = (plan_content.get('assessment') or \n",
    "                          plan_content.get('assessments') or \n",
    "                          plan_content.get('checkpoints', []))\n",
    "            if assessments:\n",
    "                print(f\"\\n{section_num}. ASSESSMENT CHECKPOINTS\")\n",
    "                if isinstance(assessments, list):\n",
    "                    for idx, assessment in enumerate(assessments, 1):\n",
    "                        if isinstance(assessment, dict):\n",
    "                            assess_name = assessment.get('name') or assessment.get('type', f'Checkpoint {idx}')\n",
    "                            assess_timing = assessment.get('timing') or assessment.get('when', '')\n",
    "                            print(f\"   {section_num}.{idx} {assess_name}\")\n",
    "                            if assess_timing:\n",
    "                                print(f\"        Timing: {assess_timing}\")\n",
    "                        else:\n",
    "                            print(f\"   {section_num}.{idx} {assessment}\")\n",
    "                elif isinstance(assessments, dict):\n",
    "                    for idx, (key, value) in enumerate(assessments.items(), 1):\n",
    "                        print(f\"   {section_num}.{idx} {key}: {value}\")\n",
    "                section_num += 1\n",
    "        \n",
    "        # Time allocation\n",
    "        if 'time_allocation' in plan_content or 'schedule' in plan_content:\n",
    "            timing = plan_content.get('time_allocation') or plan_content.get('schedule', {})\n",
    "            if timing:\n",
    "                print(f\"\\n{section_num}. TIME ALLOCATION\")\n",
    "                if isinstance(timing, dict):\n",
    "                    for idx, (section, time) in enumerate(timing.items(), 1):\n",
    "                        print(f\"   {section_num}.{idx} {section}: {time}\")\n",
    "                elif isinstance(timing, list):\n",
    "                    for idx, item in enumerate(timing, 1):\n",
    "                        print(f\"   {section_num}.{idx} {item}\")\n",
    "    \n",
    "    # If it's unstructured text, just display it\n",
    "    elif isinstance(plan_content, str):\n",
    "        print(\"\\nPLAN CONTENT:\")\n",
    "        print(plan_content)\n",
    "    \n",
    "    # Content analysis summary\n",
    "    content_analysis = lesson_plan.get('content_analysis', {})\n",
    "    if content_analysis and content_analysis.get('total_sections'):\n",
    "        print(\"\\n\" + \"-\"*80)\n",
    "        print(\"\\nCONTENT ANALYSIS:\")\n",
    "        print(f\"   Total sections available: {content_analysis.get('total_sections')}\")\n",
    "        print(f\"   Topics: {', '.join(content_analysis.get('topics', [])[:5])}\")\n",
    "        print(f\"   Difficulty levels: {', '.join(content_analysis.get('difficulty_levels', []))}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "print(\"Hierarchical lesson plan display function created!\")\n",
    "print(\"Usage: display_lesson_plan_hierarchical(lesson_plan)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070ec14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Process Rich Dad Poor Dad PDF\n",
    "print(\"=\"*80)\n",
    "print(\"TEST 1: PDF PROCESSING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "pdf_path = r\"c:\\Users\\dhanu\\OneDrive\\Desktop\\last MAS\\Rich Dad Poor Dad.pdf\"\n",
    "\n",
    "print(f\"\\nProcessing: Rich Dad Poor Dad.pdf\")\n",
    "print(\"Please wait...\\n\")\n",
    "\n",
    "try:\n",
    "    text_chunks, images = pdf_processor.process_pdf(pdf_path)\n",
    "    pdf_processor.ingest_to_qdrant(text_chunks, images)\n",
    "    \n",
    "    print(\"\\nPDF processing complete!\")\n",
    "    print(f\"Stored {len(text_chunks)} text chunks in Qdrant\")\n",
    "    print(f\"Stored {len(images)} images in Qdrant\")\n",
    "    print(\"\\nSample content from first chunk:\")\n",
    "    if text_chunks:\n",
    "        print(text_chunks[0]['payload']['text'][:200] + \"...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nError: {str(e)}\")\n",
    "    print(\"\\nMake sure you've run all previous cells (3-18) to initialize the classes.\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a70d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Generate Lesson Plan\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST 2: LESSON PLAN GENERATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    lesson_plan = planner.generate_lesson_plan(\n",
    "        learning_objectives=\"Master financial literacy concepts from Rich Dad Poor Dad\",\n",
    "        target_duration=120,\n",
    "        difficulty_preference=\"progressive\"\n",
    "    )\n",
    "    \n",
    "    if lesson_plan.get('status') == 'error':\n",
    "        print(f\"Error: {lesson_plan.get('message')}\")\n",
    "    else:\n",
    "        print(\"\\nLesson plan generated successfully!\")\n",
    "        print(f\"Version: {lesson_plan.get('version')}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nError generating lesson plan: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091556dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Display Lesson Plan in Hierarchical Format\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST 3: HIERARCHICAL LESSON PLAN DISPLAY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    if 'lesson_plan' in dir() and lesson_plan:\n",
    "        display_lesson_plan_hierarchical(lesson_plan)\n",
    "    else:\n",
    "        print(\"\\nNo lesson plan available. Run Test 2 first.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nError displaying lesson plan: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d12ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: Check the actual lesson plan structure\n",
    "if 'lesson_plan' in dir() and lesson_plan:\n",
    "    print(\"Lesson plan keys:\", lesson_plan.keys())\n",
    "    print(\"\\nPlan content type:\", type(lesson_plan.get('plan')))\n",
    "    print(\"\\nPlan content preview:\")\n",
    "    plan_content = lesson_plan.get('plan', {})\n",
    "    if isinstance(plan_content, dict):\n",
    "        print(\"Keys:\", plan_content.keys())\n",
    "        import json\n",
    "        print(json.dumps(plan_content, indent=2))\n",
    "    else:\n",
    "        print(str(plan_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa98f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick view: Show lesson plan structure\n",
    "if 'lesson_plan' in dir() and lesson_plan:\n",
    "    plan = lesson_plan.get('plan', {})\n",
    "    \n",
    "    # Check for lessons\n",
    "    if 'lessons' in plan:\n",
    "        lessons = plan['lessons']\n",
    "        print(f\"Found {len(lessons)} lessons in the plan:\")\n",
    "        print(\"\\nLesson Structure:\")\n",
    "        for lesson in lessons[:5]:  # Show first 5\n",
    "            lesson_num = lesson.get('lessonNumber', '?')\n",
    "            title = lesson.get('title', 'No title')\n",
    "            subsections = lesson.get('subsections', [])\n",
    "            has_quiz = lesson.get('quizAfter', False)\n",
    "            \n",
    "            print(f\"\\n{lesson_num}. {title}\")\n",
    "            print(f\"   Subsections: {len(subsections)}\")\n",
    "            if subsections:\n",
    "                for sub in subsections[:3]:  # Show first 3\n",
    "                    print(f\"   - {sub.get('number', '')}: {sub.get('title', '')}\")\n",
    "            if has_quiz:\n",
    "                print(f\"   [QUIZ AFTER THIS LESSON]\")\n",
    "        \n",
    "        if len(lessons) > 5:\n",
    "            print(f\"\\n... and {len(lessons) - 5} more lessons\")\n",
    "    else:\n",
    "        print(\"No 'lessons' key found in plan\")\n",
    "        print(\"Plan keys:\", plan.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccde242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Complete Teaching Flow with Lesson Plan\n",
    "print(\"=\"*80)\n",
    "print(\"EXAMPLE: TEACHING FLOW FOLLOWING LESSON PLAN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get first lesson from plan\n",
    "if 'lesson_plan' in dir() and lesson_plan:\n",
    "    plan = lesson_plan.get('plan', {})\n",
    "    lessons = plan.get('lessons', [])\n",
    "    \n",
    "    if lessons:\n",
    "        first_lesson = lessons[0]\n",
    "        print(f\"\\nLesson {first_lesson.get('lessonNumber')}: {first_lesson.get('title')}\")\n",
    "        print(f\"Duration: {first_lesson.get('duration')} minutes\")\n",
    "        print(f\"\\nSubsections to teach:\")\n",
    "        \n",
    "        for subsection in first_lesson.get('subsections', []):\n",
    "            sub_num = subsection.get('number')\n",
    "            sub_title = subsection.get('title')\n",
    "            seq_start = subsection.get('sequenceStart', 0)\n",
    "            seq_end = subsection.get('sequenceEnd', 10)\n",
    "            \n",
    "            print(f\"\\n  {sub_num} {sub_title}\")\n",
    "            print(f\"      Content sections: {seq_start}-{seq_end}\")\n",
    "            \n",
    "            # Show how to retrieve this content\n",
    "            print(f\"      To teach: session.teach_topic('{sub_title}', sequence_id={seq_start})\")\n",
    "        \n",
    "        print(f\"\\n  After completing all subsections:\")\n",
    "        if first_lesson.get('quizAfter'):\n",
    "            print(f\"      Run: quiz = session.checkpoint_quiz('{first_lesson.get('title')}')\")\n",
    "            print(f\"      Then: session.submit_quiz_answers(quiz['quiz_id'], answers)\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"This creates a structured teaching session following the actual PDF content!\")\n",
    "        print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Test Student Session\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TEST 4: ADAPTIVE TUTORING SESSION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Initialize a test student\n",
    "    test_student = \"student_001\"\n",
    "    print(f\"\\nInitializing session for: {test_student}\")\n",
    "    \n",
    "    # Create session\n",
    "    session = AdaptiveTutoringSessionV2(test_student, lesson_plan if 'lesson_plan' in dir() else None)\n",
    "    \n",
    "    print(\"\\nSession initialized successfully!\")\n",
    "    print(\"Student profile created\")\n",
    "    print(\"\\nYou can now interact with the session using:\")\n",
    "    print(\"- session.teach_topic('topic_name')\")\n",
    "    print(\"- session.process_student_input('student message')\")\n",
    "    print(\"- session.checkpoint_quiz('topic_name')\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nError initializing session: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

